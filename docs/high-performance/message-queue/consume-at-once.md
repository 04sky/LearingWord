---
title: å®ç°Kafkaè‡³å°‘æˆåŠŸæ¶ˆè´¹ä¸€æ¬¡
author: sky
date: 2022-12-18 21:07:11
permalink: /high-performance/message-queue/consume-at-once/
categories:
  - message-queue
tags:
  - æ¶ˆæ¯é˜Ÿåˆ—
---

# å®ç°Kafkaè‡³å°‘æ¶ˆè´¹ä¸€æ¬¡

> åœ¨å®é™…é‡è¦çš„åœºæ™¯ä¸­ï¼Œå¸¸å¸¸éœ€è¦å®ç°æ¶ˆè´¹è€…è‡³å°‘æ¶ˆè´¹ä¸€æ¬¡ã€‚å› ä¸ºä½¿ç”¨é»˜è®¤çš„kafkaæ¶ˆè´¹è€…å­˜åœ¨æŸäº›é—®é¢˜ã€‚

## é»˜è®¤çš„kafkaæ¶ˆè´¹è€…å­˜åœ¨ä»€ä¹ˆé—®é¢˜ï¼Ÿ

ï¼ˆ1ï¼‰éœ€è¦è‡ªå·±å®ç°é‡æ–°æ¶ˆè´¹æ•°æ®

> åœ¨åˆšå¼€å§‹æ€è€ƒæ—¶ï¼Œæœ‰äººè®¤ä¸ºå®ç°é‡å¤æ¶ˆè´¹è¿˜ä¸ç®€å•ï¼Ÿå–æ¶ˆè‡ªåŠ¨æäº¤ï¼Œç¡®è®¤ä¸€æ‰¹æ¶ˆæ¯å·²ç»æ¶ˆè´¹æˆåŠŸå°±æ‰§è¡Œæ‰‹åŠ¨æäº¤ï¼Œå¦åˆ™ä¸æäº¤ï¼›ä¹‹åé‡æ–°è·å–æœªæäº¤çš„æ•°æ®ï¼Œå°±å¯ä»¥è¾¾åˆ°é‡å¤æ¶ˆè´¹çš„ç›®çš„ã€‚ 
> 
> å¯æ˜¯ï¼Œäº‹å®æ˜¯æ®‹é…·çš„ï¼Œè¯•ä¸€æ¬¡å°±çŸ¥é“ï¼Œæ„Ÿè§‰æ‰‹åŠ¨ä¸æäº¤æ²¡æœ‰ç”¨ä¸€æ ·ğŸ˜‚ï¼Œæ¶ˆè´¹è€…ä¸€ç›´åœ¨å¾€åæ¶ˆè´¹ã€‚

å¯¹äºKafkaä¸­çš„åˆ†åŒºè€Œè¨€ï¼Œå®ƒçš„æ¯æ¡æ¶ˆæ¯éƒ½æœ‰å”¯ä¸€çš„ offset ï¼Œç”¨æ¥è¡¨ç¤ºæ¶ˆæ¯åœ¨åˆ†åŒºä¸­å¯¹åº”çš„ä½ç½®ï¼ˆcalledï¼šåç§»é‡ï¼‰ã€‚ å¯¹äºæ¶ˆè´¹è€…è€Œè¨€ï¼Œå®ƒä¹Ÿæœ‰ä¸€ä¸ª offset çš„æ¦‚å¿µï¼Œæ¶ˆè´¹è€…ä½¿ç”¨offsetæ¥è¡¨ç¤ºæ¶ˆè´¹åˆ°åˆ†åŒºä¸­æŸä¸ªæ¶ˆæ¯æ‰€åœ¨çš„ä½ç½®ï¼ˆcalledï¼šä½ç§»ï¼‰ã€‚åç§»é‡å­˜å‚¨åœ¨Kafkaå†…éƒ¨çš„ä¸»é¢˜ __consumer_offsets ä¸­ï¼Œè€Œä½ç§»å­˜å‚¨åœ¨æ¶ˆè´¹è€…ç«¯çš„å†…å­˜ä¸­ã€‚â€œæäº¤â€å°±æ˜¯å°†æ¶ˆè´¹è€…ç«¯å­˜å‚¨çš„ä½ç§»å­˜å‚¨åˆ° __consumer_offsets æŒä¹…åŒ–ï¼Œå½“æ¶ˆè´¹è€…å‘ç”Ÿå´©æºƒæˆ–å‘ç”Ÿæ¶ˆè´¹è€…é‡å¹³è¡¡æ—¶ï¼Œå°±ä¼šå»è¯»å–å­˜å‚¨åœ¨ __consumer_offsets ä¸­çš„åç§»é‡ï¼Œå…¶ä»–æ­£å¸¸æƒ…å†µä¸‹éƒ½æ˜¯æŒ‰å†…å­˜å­˜å‚¨çš„ä½ç§»åœ¨é¡ºåºè¯»å–ã€‚å› æ­¤ï¼ŒæŒ‰ç…§ä¸Šè¿°æ“ä½œå°±ä¼šå‡ºç°æäº¤æ²¡ç”¨çš„æ•ˆæœã€‚

ï¼ˆ2ï¼‰è‡ªåŠ¨æäº¤æƒ…å†µä¸‹ï¼Œå¯èƒ½å‡ºç°æ¶ˆæ¯ä¸¢å¤±æƒ…å†µ
æ‹‰å–çº¿ç¨‹ A ä¸æ–­åœ°æ‹‰å–æ¶ˆæ¯å¹¶å­˜å…¥æœ¬åœ°ç¼“å­˜ï¼Œæ¯”å¦‚åœ¨ BlockingQueue ä¸­ï¼Œå¦ä¸€ä¸ªå¤„ç†çº¿ç¨‹ B ä»ç¼“å­˜ä¸­è¯»å–æ¶ˆæ¯å¹¶è¿›è¡Œç›¸åº”çš„é€»è¾‘å¤„ç†ã€‚å‡è®¾ç›®å‰è¿›è¡Œåˆ°äº†ç¬¬ y+1 æ¬¡æ‹‰å–ï¼Œä»¥åŠç¬¬ m æ¬¡ä½ç§»æäº¤çš„æ—¶å€™ï¼Œä¹Ÿå°±æ˜¯ x+6 ä¹‹å‰çš„ä½ç§»å·±ç»ç¡®è®¤æäº¤äº†ï¼Œå¤„ç†çº¿ç¨‹ B å´è¿˜æ­£åœ¨æ¶ˆè´¹ x+3 çš„æ¶ˆæ¯ ã€‚ æ­¤æ—¶å¦‚æœå¤„ç†çº¿ç¨‹B å‘ç”Ÿäº†å¼‚å¸¸ï¼Œå¾…å…¶æ¢å¤ä¹‹åä¼šä»ç¬¬ m æ¬¡ä½ç§»æäº¤å¤„ï¼Œä¹Ÿå°±æ˜¯ x+6 çš„ä½ç½®å¼€å§‹æ‹‰å–æ¶ˆæ¯ï¼Œé‚£ä¹ˆ x+3 è‡³ x+6 ä¹‹é—´çš„æ¶ˆæ¯å°±æ²¡æœ‰å¾—åˆ°ç›¸åº”çš„å¤„ç†ï¼Œè¿™æ ·ä¾¿å‘ç”Ÿæ¶ˆæ¯ä¸¢å¤±çš„ç°è±¡ ã€‚

![kafka-msg-drop.png](../../.vuepress/public/png/kafka-msg-drop.png)

## å®ç°è‡³å°‘æ¶ˆè´¹ä¸€æ¬¡

> è¯­è¨€ï¼špython 3.8
> å·¥å…·ï¼šconfluent-kafka

ç›®å‰æœ‰2ä¸ªæ€è·¯ï¼Œç¬¬1ä¸ªæ—¶æ–°å»ºä¸€ä¸ªé‡è¯•é˜Ÿåˆ—ï¼Œå½“é‡åˆ°é—®é¢˜æ¶ˆæ¯æ—¶å°†å…¶æ’å…¥åˆ°é‡è¯•é˜Ÿåˆ—ä¸­ï¼Œæ¶ˆè´¹è€…å¯ä»¥å†æ¬¡è·å–åˆ°è¯¥é—®é¢˜æ¶ˆæ¯å¹¶å†æ¬¡æ¶ˆè´¹ã€‚ç¬¬2ä¸ªæ˜¯é€šè¿‡ seek æ–¹æ³•è®¾ç½®ä½ç§»åˆ°æŒ‡å®šå‘ç”Ÿé—®é¢˜çš„ä½ç½®ï¼Œä½¿å¾—é‡æ–°æ¶ˆè´¹é—®é¢˜æ¶ˆæ¯ï¼›

### åŠ å…¥é‡è¯•é˜Ÿåˆ—å†æ¬¡æ¶ˆè´¹
```python
class KafkaAtLeastOnceConsumer(object):
    """
    æ³¨æ„ï¼š
    1. ç”¨æˆ·æ–¹æ³•é¡»è¿”å›Booleanç±»å‹æ•°æ®ï¼ŒFalseå°†å¯èƒ½é‡æ–°æ¶ˆè´¹è¯¥æ•°æ®
    2. ç”¨æˆ·æ¶ˆæ¯å†…å®¹ä¸å¾—åŒ…å« try_countã€old_topic å…³é”®å­—

    """

    run_flag = True
    if config.DEBUG:
        total_set = set()

    def __init__(
            self,
            group_id: str,
            topic_list: List,
            user_function: Callable,
            servers: List = config.KAFKA_HOST,
            consumer_count: int = 5,
            reset_type: str = 'latest',
            concurrency: int = 5,
            batch_size: int = 500,
            timeout: int = 1,
            base_mode: bool = False,
            retry_count: int = 3,
    ):
        assert consumer_count > 0, 'æ¶ˆè´¹è€…æ•°ç›®é¡»å¤§äº0'
        assert concurrency > 0, 'æ¶ˆè´¹è€…å¹¶å‘åº¦é¡»å¤§äº0'
        assert batch_size > concurrency, 'å•æ‰¹æ¶ˆæ¯æ•°é¡»å¤§äºå¹¶å‘åº¦'
        assert timeout > 0, 'è·å–æ¶ˆæ¯è¶…æ—¶æ—¶é—´é¡»å¤§äº0'
        assert retry_count > -2, 'é‡è¯•æ¬¡æ•°åº”å¤§äºç­‰äº-1'

        self._consumer_count = consumer_count
        self._pool = ThreadPoolExecutor(max_workers=self._consumer_count)
        self._servers = ','.join(servers)
        self._group_id = group_id
        self._user_function = user_function
        self._reset_type = reset_type
        self._topic_list = topic_list
        self._concurrency = concurrency
        self._batch_size = batch_size
        self._timeout = timeout
        self._retry_count = retry_count

        self._process_num_per_thread = 100
        self._retry_topic_name = 'kfk_retry_queue'
        self._inner_producer = None

        self._topic_list.append(self._retry_topic_name)
        if base_mode:
            self._retry_count = 0

    def start(self) -> None:
        for i in range(self._consumer_count):
            self._pool.submit(self._core)

    def shutdown(self) -> None:
        KafkaAtLeastOnceConsumer.run_flag = False

    def _split_msgs(self, msgs: List) -> List:
        msg_num = len(msgs)
        if msg_num <= self._process_num_per_thread * self._concurrency:
            process_num_per_thread = self._process_num_per_thread
        else:
            process_num_per_thread = int(msg_num / self._concurrency)
        return list(chunked(msgs, process_num_per_thread))

    def _core(self) -> None:
        try:
            consumer = self._init_consumer()
            batch_pool = ThreadPoolExecutor(max_workers=self._concurrency)
            while KafkaAtLeastOnceConsumer.run_flag:
                msgs = consumer.consume(num_messages=self._batch_size, timeout=self._timeout)
                if not msgs:
                    continue
                if config.DEBUG:
                    log.info(f'å¼€å§‹å¤„ç†ä¸€æ‰¹æ¶ˆæ¯')
                msg_lists = self._split_msgs(list(msgs))
                threads = []
                for msg_list in msg_lists:
                    t = batch_pool.submit(self._thread_run, msg_list)
                    threads.append(t)
                wait(threads)
                consumer.commit()
                if config.DEBUG:
                    log.info(f'å®Œæˆå¤„ç†ä¸€æ‰¹æ¶ˆæ¯')
                    log.info(f'total_set:{len(KafkaAtLeastOnceConsumer.total_set)}')
                    time.sleep(1)
        except Exception as e:
            log.exception(e)
        finally:
            try:
                if consumer:
                    consumer.close()
                if batch_pool:
                    batch_pool.shutdown()
            except Exception as e:
                log.exception(e)

    def _thread_run(self, msg_list) -> None:
        for msg in msg_list:
            msg_map = json.loads(msg.value().decode('utf-8'))
            if 'old_topic' in msg_map and msg_map['old_topic'] not in self._topic_list:
                continue

            try:
                func_is_success = self._user_function(msg)
            except Exception:
                func_is_success = False

            if not func_is_success:
                if msg.topic() == self._retry_topic_name:
                    try_count = msg_map.get('try_count', 0)
                else:
                    try_count = 0
                if self._retry_count == 0 or (0 < self._retry_count <= try_count):
                    continue
                else:
                    # é‡è¯•æ“ä½œ
                    if not self._inner_producer:
                        self._inner_producer = self._init_producer()
                    msg_map['try_count'] = try_count + 1
                    msg_map['old_topic'] = self._topic_list[0]
                    self._inner_producer.produce(self._retry_topic_name, json.dumps(msg_map))
            elif config.DEBUG:
                KafkaAtLeastOnceConsumer.total_set.add(json.loads(msg.value().decode('utf-8'))['t'])

    def _init_consumer(self) -> Consumer:
        _consumer = Consumer(
            {
                'bootstrap.servers': self._servers,
                'group.id': self._group_id,
                'auto.offset.reset': self._reset_type,
                'enable.auto.commit': False,
            }
        )
        _consumer.subscribe(self._topic_list)
        return _consumer

    def _init_producer(self) -> Producer:
        _producer = Producer(
            {
                'bootstrap.servers': ','.join(config.KAFKA_HOST),
            }
        )
        return _producer
```

1. åŒæ—¶å¼€å¯ consumer_count ä¸ªæ¶ˆè´¹è€…å¹¶å¤„äºåŒä¸€åˆ†ç»„ä¸­ï¼Œä¸ºäº†æé«˜ååé‡ï¼Œæ¯ä¸ªæ¶ˆè´¹è€…åˆä¼šå¼€å¯ concurrency ä¸ªçº¿ç¨‹å»æ¶ˆè´¹æ•°æ®
2. å½“æ¶ˆè´¹æ¶ˆè´¹å‡ºç°å¼‚å¸¸æˆ–è¿”å›Falseï¼Œå¹¶ä¸”é‡è¯•æ¬¡æ•°æ²¡æœ‰ä½¿ç”¨å®Œæ¯•ï¼Œå°±ä¼šå°†åˆå§‹æ¶ˆæ¯ä»¥åŠé‡è¯•æ¬¡æ•°å‘é€åˆ°â€œé‡è¯•é˜Ÿåˆ—â€
3. å…³é—­è‡ªåŠ¨æäº¤ï¼Œå¼€å¯æ‰‹åŠ¨æäº¤ï¼Œå½“æ¶ˆè´¹è€…ç«¯å´©æºƒæˆ–å†å¹³è¡¡æ—¶å†æ¬¡æ¶ˆè´¹æœªæäº¤æ•°æ®ã€‚


æµ‹è¯•ä»£ç ï¼š
```python
def _get_msg_data(msg):
    p = msg.partition()
    o = msg.offset()
    t = msg.topic()
    value = msg.value().decode('utf-8')
    return p, o, t, value


def my_function(msg):
    if msg.error():
        log.error('fetch msg is error. error:%s' % msg.error())
        return False
    # å¤„ç†ä¸šåŠ¡é€»è¾‘ï¼Œå•æ¬¡é—®é¢˜è¿›è¡Œé‡è¯•
    p, o, t, value = _get_msg_data(msg)
    if random.randint(1, 100) == 9:
        log.info(f"å‘ç”Ÿä¸šåŠ¡å¼‚å¸¸è¿”å›False, topic:{t}, partition:{p},  offset {o}, value:{value['t']} ")
        return False
    else:
        log.info(f'ä¸šåŠ¡å¤„ç†æ¶ˆæ¯ï¼Œtopic:{t}, partition:{p}, offset:{o}, content:{value}')
        return True


def success_function(msg):
    # å¤„ç†ä¸šåŠ¡é€»è¾‘ï¼Œå®Œå…¨æ­£å¸¸
    if msg.error():
        log.error('fetch msg is error. error:%s' % msg.error())
        return False
    p, o, t, value = _get_msg_data(msg)
    log.info(f'ä¸šåŠ¡å¤„ç†æ¶ˆæ¯ï¼Œtopic:{t}, partition:{p}, offset:{o}, content:{value}')
    return True


def exception_function(msg):
    # å¤„ç†ä¸šåŠ¡é€»è¾‘ï¼ŒæŠ›å‡ºå¼‚å¸¸é‡è¯•
    if msg.error():
        log.error('fetch msg is error. error:%s' % msg.error())
        return False
    p, o, t, value = _get_msg_data(msg)
    if random.randint(1, 100) == 9:
        log.info(f"å‘ç”Ÿä¸šåŠ¡å¼‚å¸¸è¿”å›False, topic:{t}, partition:{p},  offset {o}, value:{value['t']} ")
        raise Exception('ä¸šåŠ¡å¼‚å¸¸')
    else:
        log.info(f'ä¸šåŠ¡å¤„ç†æ¶ˆæ¯ï¼Œtopic:{t}, partition:{p}, offset:{o}, content:{value}')
        return True


def test_normal_try_limit(retry_count):
    # ç”¨æˆ·å‡½æ•°è¿”å›falseé‡è¯•(-1æ— é™/æ•°å­—ä¸ºé‡è¯•æ¬¡æ•°)
    consumer = KafkaAtLeastOnceConsumer(group_id, [topic], my_function, retry_count=retry_count)
    consumer.start()
    while True:
        time.sleep(10)


def test_exception_try_limit(retry_count):
    # å¼‚å¸¸æŒ‡å®šé‡è¯•æ¬¡æ•°(-1æ— é™/æ•°å­—ä¸ºé‡è¯•æ¬¡æ•°)
    consumer = KafkaAtLeastOnceConsumer(group_id, [topic], exception_function, retry_count=retry_count)
    consumer.start()
    while True:
        time.sleep(10)


def test_normal_no_try():
    # åŸºæœ¬æ¨¡å¼
    consumer = KafkaAtLeastOnceConsumer(group_id, [topic], my_function, base_mode=True)
    consumer.start()
    while True:
        time.sleep(10)


def test_crash_consume():
    # æ¨¡æ‹Ÿæ¶ˆè´¹è€…å…³åœ/å´©æºƒï¼Œæ¶ˆè´¹è€…ç»§ç»­æ¶ˆè´¹
    consumer = KafkaAtLeastOnceConsumer(group_id, [topic], success_function, base_mode=True)
    consumer.start()
    time.sleep(20)
    consumer.shutdown()


if __name__ == '__main__':
    test_channel = sys.argv[1]
    if test_channel == "1":
        test_normal_try_limit(-1)
    elif test_channel == "2":
        test_normal_try_limit(3)
    elif test_channel == "3":
        test_exception_try_limit(-1)
    elif test_channel == "4":
        test_exception_try_limit(3)
    elif test_channel == "5":
        test_normal_no_try()
    elif test_channel == "6":
        test_crash_consume()
    else:
        test_normal_try_limit(-1)
```

### ä½¿ç”¨seekæ–¹æ³•å†æ¬¡æ¶ˆè´¹

ç†è®ºä¸Šæ¥è®²ï¼Œè¿™ç§æ–¹æ³•æ˜¯èƒ½è¡Œçš„é€šçš„ã€‚å› ä¸ºseekèƒ½å°†ä¸€ä¸ªæ´»è·ƒåˆ†åŒºçš„æ¶ˆè´¹ä½ç§»è®¾ç½®åˆ°æ¶ˆè´¹å¤±è´¥çš„ä½ç½®ï¼Œç„¶åä¸‹ä¸€æ¬¡æ‹‰å–æ—¶å¯ä»¥é‡æ–°è·å–è¯¥æ•°æ®ï¼Œå¹¶ä¸”ç›¸æ¯”ä½¿ç”¨â€œé‡è¯•é˜Ÿåˆ—â€ï¼Œseekæ–¹å¼è¿˜å¯ä»¥ä¿è¯æ¶ˆæ¯éƒ¨åˆ†é¡ºåºã€‚
ä½†æ˜¯seekåœ¨æ‰¹é‡å¤„ç†ä¸‹å­˜åœ¨[æœªçŸ¥é—®é¢˜](https://github.com/confluentinc/confluent-kafka-python/issues/1443)ï¼Œåé¢å†ç ”ç©¶ã€‚
